{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引用Web Server套件\n",
    "from flask import Flask, request, abort\n",
    "\n",
    "# 從linebot 套件包裡引用 LineBotApi 與 WebhookHandler 類別\n",
    "from linebot import (\n",
    "    LineBotApi, WebhookHandler\n",
    ")\n",
    "\n",
    "# \n",
    "from linebot.exceptions import (\n",
    "    InvalidSignatureError\n",
    ")\n",
    "\n",
    "# 將消息模型，文字收取消息與文字寄發消息 引入\n",
    "from linebot.models import (\n",
    "    MessageEvent, TextMessage, TextSendMessage, ImageMessage, AudioMessage\n",
    ")\n",
    "\n",
    "# 載入設定檔\n",
    "\n",
    "import json\n",
    "secretFileContentJson=json.load(open(\"./line_secret_key\",'r'))\n",
    "server_url=secretFileContentJson.get(\"server_url\")\n",
    "\n",
    "\n",
    "# 設定Server啟用細節\n",
    "app = Flask(__name__,static_url_path = \"/images\" , static_folder = \"./images/\" )\n",
    "\n",
    "# 生成實體物件\n",
    "line_bot_api = LineBotApi(secretFileContentJson.get(\"channel_access_token\"))\n",
    "handler = WebhookHandler(secretFileContentJson.get(\"secret_key\"))\n",
    "\n",
    "# 啟動server對外接口，使Line能丟消息進來\n",
    "@app.route(\"/\", methods=['POST'])\n",
    "def callback():\n",
    "    # get X-Line-Signature header value\n",
    "    signature = request.headers['X-Line-Signature']\n",
    "\n",
    "    # get request body as text\n",
    "    body = request.get_data(as_text=True)\n",
    "    app.logger.info(\"Request body: \" + body)\n",
    "\n",
    "    # handle webhook body\n",
    "    try:\n",
    "        handler.handle(body, signature)\n",
    "    except InvalidSignatureError:\n",
    "        abort(400)\n",
    "\n",
    "    return 'OK'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 載入Follow事件\n",
    "from linebot.models.events import (\n",
    "    FollowEvent\n",
    ")\n",
    "\n",
    "# 載入requests套件\n",
    "import requests\n",
    "\n",
    "\n",
    "# 告知handler，如果收到FollowEvent，則做下面的方法處理\n",
    "@handler.add(FollowEvent)\n",
    "def reply_text_and_get_user_profile(event):\n",
    "    \n",
    "    # 取出消息內User的資料\n",
    "    user_profile = line_bot_api.get_profile(event.source.user_id)\n",
    "        \n",
    "     # 將用戶資訊存在檔案內\n",
    "    with open(\"./users.txt\", \"a\") as myfile:\n",
    "        myfile.write(json.dumps(vars(user_profile),sort_keys=True))\n",
    "        myfile.write('\\r\\n')\n",
    "        \n",
    "        \n",
    "#     # 將菜單綁定在用戶身上\n",
    "#     linkRichMenuId=secretFileContentJson.get(\"rich_menu_id\")\n",
    "#     linkResult=line_bot_api.link_rich_menu_to_user(secretFileContentJson[\"self_user_id\"], linkRichMenuId)\n",
    "    \n",
    "#     # 回覆文字消息與圖片消息\n",
    "#     line_bot_api.reply_message(\n",
    "#         event.reply_token,\n",
    "#         reply_message_list\n",
    "#     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PushMessage(context):\n",
    "    #推播消息\n",
    "    from linebot import LineBotApi\n",
    "    from linebot.models import TextSendMessage\n",
    "    from linebot.exceptions import LineBotApiError\n",
    "\n",
    "    token = \"AhuuqOghydZqwlCbgOHo/JJxADgxz3begLh9bzoK7nCja4ipotAl9pnKi5YAX+1eip/O65jb+4J7kdsOcVf4lViTf/RJiKymXsctgk0gS9WhD8KeNtn1WRgICzk8I3a2oQpDWx4fXcNZfcsPA1chUgdB04t89/1O/w1cDnyilFU=\"\n",
    "\n",
    "    line_bot_api = LineBotApi(token)\n",
    "\n",
    "    try:\n",
    "        line_bot_api.push_message('Ubbe1a0ecaf2b210fd618c919d1d19870', TextSendMessage(text=context))\n",
    "    except LineBotApiError as e:\n",
    "        print(\"error handle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aip import AipSpeech\n",
    "import json\n",
    "import time\n",
    "import os\n",
    "import wave\n",
    "from pydub import AudioSegment\n",
    "from predict import *  ## * 很重要,pip install才可以直接import 自製的py檔要加*\n",
    "from Voice2Text import *\n",
    "\n",
    "\n",
    "#情感分析\n",
    "def emotion_predict(text):\n",
    "    sm = sentimentModel(text)\n",
    "    #clear_output()\n",
    "    model = sm.loadModel(sm.modelPath)\n",
    "\n",
    "    print(f\"要預測的話:\\n{text}\")\n",
    "    print(\"=\"*25 + \"開始預測\" + \"=\"*25)\n",
    "    token_tensor, segment_tensor, mask_tensor = sm.convert_text_to_bertEat(text)\n",
    "    pred_num, pred = sm.sentimentPredict(model, token_tensor, segment_tensor, mask_tensor)\n",
    "\n",
    "    sign = sm.pass_sign_to_lineAndgui_or_nextModel(pred_num)\n",
    "    \n",
    "    print(f\"預測結果為:{pred}\")\n",
    "    print(\"=\"*25 + \"預測結束\" + \"=\"*25)\n",
    "    \n",
    "    return sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@handler.add(MessageEvent, message=AudioMessage)\n",
    "def handle_message(event):\n",
    "    #接收資料,回傳一段訊息給用戶,並將資料取回本機\n",
    "    line_bot_api.reply_message(\n",
    "        event.reply_token,\n",
    "        TextSendMessage(text='沒事亂傳訊息，害我又要加班'))\n",
    "    message_content = line_bot_api.get_message_content(event.message.id)\n",
    "    with open('./audios/'+event.message.id+\".aac\", 'wb') as fd: ###LINE預設音檔是.aac\n",
    "        for chunk in message_content.iter_content():\n",
    "            fd.write(chunk)\n",
    "            \n",
    "    #####這邊要加入語音轉文字#####\n",
    "    voice_to_txt()\n",
    "    \n",
    "    #####接著情感分析#####\n",
    "    predict = emotion_predict(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://0.0.0.0:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [04/Nov/2019 20:43:06] \"POST / HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [04/Nov/2019 20:43:09] \"POST / HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    app.run(host='0.0.0.0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "信用卡申辦\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'torch' has no attribute 'tensor'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-8b13578b57e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[0mtext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"信用卡申辦\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0memotion_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-24-8b13578b57e9>\u001b[0m in \u001b[0;36memotion_predict\u001b[1;34m(text)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0msm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msentimentModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;31m#clear_output()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 13\u001b[1;33m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloadModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"要預測的話:\\n{text}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\新增資料夾 (2)\\Line_Chat_Bot-master\\predict.py\u001b[0m in \u001b[0;36mloadModel\u001b[1;34m(self, modelPath)\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;31m# load model and set to cuda if they are here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodelPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    424\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;34m'encoding'\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m             \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 426\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    427\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnew_fd\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_load\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    611\u001b[0m     \u001b[0munpickler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mUnpickler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    612\u001b[0m     \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpersistent_load\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpersistent_load\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 613\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0munpickler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    614\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    615\u001b[0m     \u001b[0mdeserialized_storage_keys\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_rebuild_tensor_v2\u001b[1;34m(storage, storage_offset, size, stride, requires_grad, backward_hooks)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    134\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_rebuild_tensor_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbackward_hooks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 135\u001b[1;33m     \u001b[0mtensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_rebuild_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    136\u001b[0m     \u001b[0mtensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequires_grad\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m     \u001b[1;31m# NB: This line exists only for backwards compatibility; the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\python\\lib\\site-packages\\torch\\_utils.py\u001b[0m in \u001b[0;36m_rebuild_tensor\u001b[1;34m(storage, storage_offset, size, stride)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_rebuild_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m     \u001b[1;31m# first construct a tensor with the correct dtype/device\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 130\u001b[1;33m     \u001b[0mt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    131\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'torch' has no attribute 'tensor'"
     ]
    }
   ],
   "source": [
    "# from aip import AipSpeech\n",
    "# import json\n",
    "# import time\n",
    "# import os\n",
    "# import wave\n",
    "# from pydub import AudioSegment\n",
    "# from predict import *  ## * 很重要,pip install才可以直接import 自製的py檔要加*\n",
    "\n",
    "# #情感分析\n",
    "# def emotion_predict(text):\n",
    "#     sm = sentimentModel(text)\n",
    "#     #clear_output()\n",
    "#     model = sm.loadModel(sm.modelPath)\n",
    "\n",
    "#     print(f\"要預測的話:\\n{text}\")\n",
    "#     print(\"=\"*25 + \"開始預測\" + \"=\"*25)\n",
    "#     token_tensor, segment_tensor, mask_tensor = sm.convert_text_to_bertEat(text)\n",
    "#     pred_num, pred = sm.sentimentPredict(model, token_tensor, segment_tensor, mask_tensor)\n",
    "\n",
    "#     sign = sm.pass_sign_to_lineAndgui_or_nextModel(pred_num)\n",
    "    \n",
    "#     print(f\"預測結果為:{pred}\")\n",
    "#     print(\"=\"*25 + \"預測結束\" + \"=\"*25)\n",
    "    \n",
    "#     return sign\n",
    "\n",
    "# #取出判別的內文\n",
    "# text = \"信用卡申辦\"\n",
    "# print(text)\n",
    "# predict = emotion_predict(str(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from aip import AipSpeech\n",
    "# import json\n",
    "# import time\n",
    "\n",
    "# \"\"\" 你的 APPID AK SK \"\"\"\n",
    "# APP_ID = '17610496'\n",
    "# API_KEY = '3HxD7AjTwLrjEdWzjno97lbl'\n",
    "# SECRET_KEY = 'rPBbzb3enl2EA0cK0n98zHktbWDqYPt8'\n",
    "\n",
    "# begin = time.time()\n",
    "# client = AipSpeech(APP_ID, API_KEY, SECRET_KEY)\n",
    "\n",
    "\n",
    "# # 读取文件\n",
    "# def get_file_content(filepath):\n",
    "#     with open(filepath, 'rb') as fp:\n",
    "#         return fp.read()\n",
    "\n",
    "\n",
    "# # 识别本地文件\n",
    "# voicefile = \"audios10832336465039.wav\"\n",
    "# # base = \"./audios/\"\n",
    "# # print(base+voicefile)\n",
    "# result = client.asr(get_file_content(voicefile), 'wav', 16000, {\n",
    "#     'dev_pid': 1536,\n",
    "# })\n",
    "# # print(result)\n",
    "# print(\"Request time cost %f\" % (time.time() - begin))\n",
    "# if result['err_no'] == 0:\n",
    "#     ofile = \"result_%s.txt\" % (voicefile)\n",
    "#     with open(ofile, \"w\", encoding=\"utf-8\") as of:\n",
    "#         json.dump(result, of, ensure_ascii=False)\n",
    "# else:\n",
    "#     print(result['err_msg'], result['err_no'])\n",
    "\n",
    "# print(\"完成了\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wave\n",
    "\n",
    "# with wave.open('./audios/10826265961358.wav', \"rb\") as f:\n",
    "#     f = wave.open('./audios/10826265961358.wav')\n",
    "#     print(f.getparams())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import librosa\n",
    "# import soundfile as sf\n",
    "# x,_ = librosa.load('./audios/10826265961358.wav', sr=16000)\n",
    "# sf.write('tmp.wav', x, 16000)\n",
    "# wave.open('tmp.wav','r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# import wave\n",
    "# os.system(r\"ffmpeg -i 10826265961358.wav b0.wav\")\n",
    "# wave.open('b0', \"r\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b=os.popen(r\"ffmpeg -y -i ./audios/10826265961358.wav  -acodec pcm_s16le -f s16le -ac 1 -ar 16000 ./audios/1082626596135800.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
